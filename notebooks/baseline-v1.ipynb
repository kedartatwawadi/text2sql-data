{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import dynet as dy # Loaded late to avoid memory allocation when we just want help info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Command line argument handling and default configuration ##\n",
    "\n",
    "abstract_lang = 'sql'\n",
    "###abstract_lang = 'logic'\n",
    "sys.argv = ['baseline_model','../data/atis.json','--do_test_eval']\n",
    "#--eval_freq 1000000 --log_freq 1000000 --max_bad_iters -1 --do_test_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='A simple template-based text-to-SQL system.')\n",
    "\n",
    "# IO\n",
    "parser.add_argument('data', help='Data in json format', nargs='+')\n",
    "parser.add_argument('--unk_max', help='Maximum count to be considered an unknown word', type=int, default=0)\n",
    "parser.add_argument('--query_split', help='Use the query split rather than the question split', action='store_true')\n",
    "parser.add_argument('--no_vars', help='Run without filling in variables', action='store_true')\n",
    "parser.add_argument('--use_all_sql', help='Default is to use first SQL only, this makes multiple instances.', action='store_true')\n",
    "parser.add_argument('--do_test_eval', help='Do the final evaluation on the test set (rather than dev).', action='store_true')\n",
    "parser.add_argument('--split', help='Use this split in cross-validation.', type=int)\n",
    "\n",
    "# Model\n",
    "parser.add_argument('--mlp', help='Use a multi-layer perceptron', action='store_true')\n",
    "parser.add_argument('--dim_word', help='Dimensionality of word embeddings', type=int, default=128)\n",
    "parser.add_argument('--dim_hidden_lstm', help='Dimensionality of LSTM hidden vectors', type=int, default=64)\n",
    "parser.add_argument('--dim_hidden_mlp', help='Dimensionality of MLP hidden vectors', type=int, default=32)\n",
    "parser.add_argument('--dim_hidden_template', help='Dimensionality of MLP hidden vectors for the final template choice', type=int, default=64)\n",
    "parser.add_argument('--word_vectors', help='Pre-built word embeddings')\n",
    "parser.add_argument('--lstm_layers', help='Number of layers in the LSTM', type=int, default=2)\n",
    "\n",
    "# Training\n",
    "parser.add_argument('--max_iters', help='Maximum number of training iterations', type=int, default=22)\n",
    "parser.add_argument('--max_bad_iters', help='Maximum number of consecutive training iterations without improvement', type=int, default=10)\n",
    "parser.add_argument('--log_freq', help='Number of examples to decode between logging', type=int, default=1000000)\n",
    "parser.add_argument('--eval_freq', help='Number of examples to decode between evaluation runs', type=int, default=500000)\n",
    "parser.add_argument('--train_noise', help='Noise added to word embeddings as regularization', type=float, default=0.1)\n",
    "parser.add_argument('--lstm_dropout', help='Dropout for input and hidden elements of the LSTM', type=float, default=0.0)\n",
    "parser.add_argument('--learning_rate', help='Learning rate for optimiser', type=float, default=\"0.05\")\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input ##\n",
    "\n",
    "def insert_variables(sql, sql_variables, sent, sent_variables):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    for token in sent.strip().split():\n",
    "        if (token not in sent_variables) or args.no_vars:\n",
    "            tokens.append(token)\n",
    "            tags.append(\"O\")\n",
    "        else:\n",
    "            assert len(sent_variables[token]) > 0\n",
    "            for word in sent_variables[token].split():\n",
    "                tokens.append(word)\n",
    "                tags.append(token)\n",
    "\n",
    "    sql_tokens = []\n",
    "    for token in sql.strip().split():\n",
    "        if token.startswith('\"%') or token.startswith(\"'%\"):\n",
    "            sql_tokens.append(token[:2])\n",
    "            token = token[2:]\n",
    "        elif token.startswith('\"') or token.startswith(\"'\"):\n",
    "            sql_tokens.append(token[0])\n",
    "            token = token[1:]\n",
    "\n",
    "        if token.endswith('%\"') or token.endswith(\"%'\"):\n",
    "            sql_tokens.append(token[:-2])\n",
    "            sql_tokens.append(token[-2:])\n",
    "        elif token.endswith('\"') or token.endswith(\"'\"):\n",
    "            sql_tokens.append(token[:-1])\n",
    "            sql_tokens.append(token[-1])\n",
    "        else:\n",
    "            sql_tokens.append(token)\n",
    "\n",
    "    template = []\n",
    "    for token in sql_tokens:\n",
    "        if (token not in sent_variables) and (token not in sql_variables):\n",
    "            template.append(token)\n",
    "        elif token in sent_variables:\n",
    "            if sent_variables[token] == '':\n",
    "                example = None\n",
    "                for variable in sql_variables:\n",
    "                    if variable['name'] == token:\n",
    "                        example = variable['example']\n",
    "                assert example is not None\n",
    "                template.append(example)\n",
    "            else:\n",
    "                template.append(token)\n",
    "        elif token in sql_variables:\n",
    "            example = None\n",
    "            for variable in sql_variables:\n",
    "                if variable['name'] == token:\n",
    "                    example = variable['example']\n",
    "            assert example is not None\n",
    "            template.append(example)\n",
    "            \n",
    "    template_tags = sorted(list(set(tags)))\n",
    "    return (tokens, tags, ' '.join(template), sent_variables )\n",
    "\n",
    "def get_tagged_data_for_query(data):\n",
    "    dataset = data['query-split']\n",
    "    for sent_info in data['sentences']:\n",
    "        if not args.query_split:\n",
    "            dataset = sent_info['question-split']\n",
    "\n",
    "        if args.split is not None:\n",
    "            if str(args.split) == str(dataset):\n",
    "                dataset = \"test\"\n",
    "            else:\n",
    "                dataset = \"train\"\n",
    "\n",
    "        for sql in data[abstract_lang]:\n",
    "            sql_vars = data['variables']\n",
    "            text = sent_info['text']\n",
    "            text_vars = sent_info['variables']\n",
    "\n",
    "            yield (dataset, insert_variables(sql, sql_vars, text, text_vars))\n",
    "\n",
    "            if not args.use_all_sql:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "dev = []\n",
    "test = []\n",
    "for filename in args.data:\n",
    "    with open(filename) as input_file:\n",
    "        data = json.load(input_file)\n",
    "        if type(data) == list:\n",
    "            for example in data:\n",
    "                for dataset, instance in get_tagged_data_for_query(example):\n",
    "                    if dataset == 'train':\n",
    "                        train.append(instance)\n",
    "                    elif dataset == 'dev':\n",
    "                        if args.do_test_eval:\n",
    "                            train.append(instance)\n",
    "                        else:\n",
    "                            dev.append(instance)\n",
    "                    elif dataset == 'test':\n",
    "                        test.append(instance)\n",
    "                    elif dataset == 'exclude':\n",
    "                        pass\n",
    "                    else:\n",
    "                        assert False, dataset\n",
    "        else:\n",
    "            for dataset, instance in get_tagged_data_for_query(data):\n",
    "                if dataset == 'train':\n",
    "                    train.append(instance)\n",
    "                elif dataset == 'dev':\n",
    "                    if args.do_test_eval:\n",
    "                        train.append(instance)\n",
    "                    else:\n",
    "                        dev.append(instance)\n",
    "                elif dataset == 'test':\n",
    "                    test.append(instance)\n",
    "                elif dataset == 'exclude':\n",
    "                    pass\n",
    "                else:\n",
    "                    assert False, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up voacbulary ##\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, w2i):\n",
    "        self.w2i = dict(w2i)\n",
    "        self.i2w = {i:w for w,i in w2i.items()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_corpus(cls, corpus):\n",
    "        w2i = {}\n",
    "        for word in corpus:\n",
    "            w2i.setdefault(word, len(w2i))\n",
    "        return Vocab(w2i)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.w2i.keys())\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    counts = Counter()\n",
    "    words = {\"<UNK>\"}\n",
    "    tag_set = set()\n",
    "    template_set = set()\n",
    "    template_to_tagset = {}\n",
    "    for tokens, tags, template, text_variables in train:\n",
    "        template_set.add(template)\n",
    "        template_to_tagset[template] = set(text_variables.keys())\n",
    "        for tag in tags:\n",
    "            tag_set.add(tag)\n",
    "        for token in tokens:\n",
    "            counts[token] += 1\n",
    "\n",
    "    for word in counts:\n",
    "        if counts[word] > args.unk_max:\n",
    "            words.add(word)\n",
    "\n",
    "    vocab_tags = Vocab.from_corpus(tag_set)\n",
    "    vocab_words = Vocab.from_corpus(words)\n",
    "    vocab_templates = Vocab.from_corpus(template_set)\n",
    "\n",
    "    return vocab_words, vocab_tags, vocab_templates, template_to_tagset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 871 templates\n"
     ]
    }
   ],
   "source": [
    "vocab_words, vocab_tags, vocab_templates,template_to_tagset = build_vocab(train)\n",
    "UNK = vocab_words.w2i[\"<UNK>\"]\n",
    "NWORDS = vocab_words.size()\n",
    "NTAGS = vocab_tags.size()\n",
    "NTEMPLATES = vocab_templates.size()\n",
    "\n",
    "print(\"Running with {} templates\".format(NTEMPLATES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    }
   ],
   "source": [
    "template_set_test = set()\n",
    "count = 0\n",
    "for tokens, tags, template, text_variables in test:\n",
    "    template_to_tagset[template] = set(text_variables.keys())\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up model ##\n",
    "\n",
    "model = dy.Model()\n",
    "trainer = dy.SimpleSGDTrainer(model, learning_rate=args.learning_rate)\n",
    "DIM_WORD = args.dim_word\n",
    "DIM_HIDDEN_LSTM = args.dim_hidden_lstm\n",
    "DIM_HIDDEN_MLP = args.dim_hidden_mlp\n",
    "DIM_HIDDEN_TEMPLATE = args.dim_hidden_template\n",
    "\n",
    "pEmbedding = model.add_lookup_parameters((NWORDS, DIM_WORD))\n",
    "if args.word_vectors is not None:\n",
    "    pretrained = []\n",
    "    with open(args.word_vectors,'rb') as pickleFile:\n",
    "        embedding = pickle.load(pickleFile)\n",
    "        for word_id in range(vocab_words.size()):\n",
    "            word = vocab_words.i2w[word_id]\n",
    "            if word in embedding:\n",
    "                pretrained.append(embedding[word])\n",
    "            else:\n",
    "                pretrained.append(pEmbedding.row_as_array(word_id))\n",
    "    pEmbedding.init_from_array(np.array(pretrained))\n",
    "if args.mlp:\n",
    "    pHidden = model.add_parameters((DIM_HIDDEN_MLP, DIM_HIDDEN_LSTM*2))\n",
    "    pOutput = model.add_parameters((NTAGS, DIM_HIDDEN_MLP))\n",
    "else:\n",
    "    pOutput = model.add_parameters((NTAGS, DIM_HIDDEN_LSTM*2))\n",
    "\n",
    "builders = [\n",
    "    dy.LSTMBuilder(args.lstm_layers, DIM_WORD, DIM_HIDDEN_LSTM, model),\n",
    "    dy.LSTMBuilder(args.lstm_layers, DIM_WORD, DIM_HIDDEN_LSTM, model),\n",
    "]\n",
    "\n",
    "pHiddenTemplate = model.add_parameters((DIM_HIDDEN_TEMPLATE, DIM_HIDDEN_LSTM*2))\n",
    "pOutputTemplate = model.add_parameters((NTEMPLATES, DIM_HIDDEN_TEMPLATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tagging_graph(words, tags, template, builders, train=True,k=1):\n",
    "    dy.renew_cg()\n",
    "\n",
    "    if train and args.lstm_dropout is not None and args.lstm_dropout > 0:\n",
    "        for b in builders:\n",
    "            b.set_dropouts(args.lstm_dropout, args.lstm_dropout)\n",
    "\n",
    "    f_init, b_init = [b.initial_state() for b in builders]\n",
    "\n",
    "    wembs = [dy.lookup(pEmbedding, w) for w in words]\n",
    "    if train: # Add noise in training as a regularizer\n",
    "        wembs = [dy.noise(we, args.train_noise) for we in wembs]\n",
    "\n",
    "    fw_states = [x for x in f_init.add_inputs(wembs)]\n",
    "    bw_states = [x for x in b_init.add_inputs(reversed(wembs))]\n",
    "    fw = [x.output() for x in fw_states]\n",
    "    bw = [x.output() for x in bw_states]\n",
    "\n",
    "    O = dy.parameter(pOutput)\n",
    "    if args.mlp:\n",
    "        H = dy.parameter(pHidden)\n",
    "    errs = []\n",
    "    pred_tags = []\n",
    "    sorted_arg_topk = []\n",
    "    final_topk = []\n",
    "    sequences_topk = [(0.0,list())]\n",
    "    for f, b, t in zip(fw, reversed(bw), tags):\n",
    "        f_b = dy.concatenate([f,b])\n",
    "        if args.mlp:\n",
    "            f_b = dy.tanh(H * f_b)\n",
    "        r_t = O * f_b\n",
    "        if train:\n",
    "            err = dy.pickneglogsoftmax(r_t, t)\n",
    "            errs.append(err)\n",
    "        else:\n",
    "            out = dy.log_softmax(r_t)\n",
    "            chosen = np.argmax(out.npvalue())\n",
    "            pred_tags.append(vocab_tags.i2w[chosen])\n",
    "            all_sequences = list()\n",
    "            for seq in sequences_topk:\n",
    "                seq_score,seq_list = seq\n",
    "                _scores = -out.npvalue()\n",
    "                arg_topk = np.argsort(_scores)[:k]\n",
    "                score_topk = _scores[arg_topk]\n",
    "                for i in range(k):\n",
    "                    _list = list(seq_list)\n",
    "                    _list.append(vocab_tags.i2w[arg_topk[i]])\n",
    "                    score = seq_score + score_topk[i]\n",
    "                    all_sequences.append((score,_list))\n",
    "            sequences_topk = sorted(all_sequences)[:k]\n",
    "            \n",
    "\n",
    "    O_template = dy.parameter(pOutputTemplate)\n",
    "    H_template = dy.parameter(pHiddenTemplate)\n",
    "    f_bt = dy.concatenate([fw_states[-1].s()[0], bw_states[-1].s()[0]])\n",
    "    f_bt = dy.tanh(H_template * f_bt)\n",
    "    r_tt = O_template * f_bt\n",
    "    pred_template = None\n",
    "    if train:\n",
    "        err = dy.pickneglogsoftmax(r_tt, template)\n",
    "        errs.append(err)\n",
    "    else:\n",
    "        out = dy.log_softmax(r_tt)\n",
    "        _scores = -out.npvalue()\n",
    "        chosen = np.argmin(_scores)        \n",
    "        pred_template = vocab_templates.i2w[chosen]\n",
    "        sorted_arg_topk = np.argsort(_scores)[:1]\n",
    "        \n",
    "        all_sequences_and_templates = []\n",
    "        for template_id in sorted_arg_topk:\n",
    "            _score = _scores[template_id]\n",
    "            _template = vocab_templates.i2w[template_id]\n",
    "\n",
    "            for seq_score,seq_list in sequences_topk:\n",
    "                all_sequences_and_templates.append((_score + seq_score, seq_list, _template))\n",
    "        final_topk = sorted(all_sequences_and_templates)[:k]    \n",
    "        \n",
    "        \n",
    "    return pred_tags, pred_template, errs, final_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dy.parameter(...) call is now DEPRECATED.\n",
      "        There is no longer need to explicitly add parameters to the computation graph.\n",
      "        Any used parameter will be added automatically.\n",
      "Stopping at iter 10 as there have been 10 iters without improvement\n"
     ]
    }
   ],
   "source": [
    "tagged = 0\n",
    "loss = 0\n",
    "best_dev_acc = 0.0\n",
    "iters_since_best_updated = 0\n",
    "steps = 0\n",
    "for iteration in range(args.max_iters):\n",
    "    random.shuffle(train)\n",
    "    for tokens, tags, template, text_variables in train:\n",
    "        steps += 1\n",
    "\n",
    "        # Convert to indices\n",
    "        word_ids = [vocab_words.w2i.get(word, UNK) for word in tokens]\n",
    "        tag_ids = [vocab_tags.w2i[tag] for tag in tags]\n",
    "        template_id = vocab_templates.w2i[template]\n",
    "\n",
    "        # Decode and update\n",
    "        _, _, errs,_ = build_tagging_graph(word_ids, tag_ids, template_id, builders)\n",
    "        sum_errs = dy.esum(errs)\n",
    "        loss += sum_errs.scalar_value()\n",
    "        tagged += len(tag_ids)\n",
    "        sum_errs.backward()\n",
    "        trainer.update()\n",
    "\n",
    "        # Log status\n",
    "        if steps % args.log_freq == 0:\n",
    "            trainer.status()\n",
    "            print(\"TrainLoss {}-{}: {}\".format(iteration, steps, loss / tagged))\n",
    "            loss = 0\n",
    "            tagged = 0\n",
    "            sys.stdout.flush()\n",
    "        if steps % args.eval_freq == 0:\n",
    "            acc = run_eval(dev, builders, iteration, steps)\n",
    "            if best_dev_acc < acc:\n",
    "                best_dev_acc = acc\n",
    "                iters_since_best_updated = 0\n",
    "                print(\"New best Acc!\", acc)\n",
    "            sys.stdout.flush()\n",
    "    iters_since_best_updated += 1\n",
    "    if args.max_bad_iters > 0 and iters_since_best_updated > args.max_bad_iters:\n",
    "        print(\"Stopping at iter {} as there have been {} iters without improvement\".format(iteration, args.max_bad_iters))\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(data, builders, iteration, step,k):\n",
    "    if len(data) == 0:\n",
    "        print(\"No data for eval\")\n",
    "        return -1\n",
    "    good = 0.0\n",
    "    total = 0.0\n",
    "    complete_good = 0.0\n",
    "    templates_good = 0.0\n",
    "    oracle = 0.0\n",
    "    tag_set_wrong = 0.0\n",
    "    inconsistent_examples = 0\n",
    "    template_error = 0.0\n",
    "    inconsistent = True\n",
    "    for tokens, tags, template, text_variables in data:\n",
    "        word_ids = [vocab_words.w2i.get(word, UNK) for word in tokens]\n",
    "        tag_ids = [0 for tag in tags]\n",
    "        pred_tags, pred_template, _ , final_topk = build_tagging_graph(word_ids, tag_ids, 0, builders, False,k=k)\n",
    "        gold_tags = tags\n",
    "        perfect = True\n",
    "        \n",
    "#         print(gold_tags)\n",
    "#         print(tokens)\n",
    "#         print(template)\n",
    "        try:\n",
    "            _temp = template_to_tagset[template]\n",
    "            _temp.add('O')\n",
    "            if _temp != set(gold_tags):\n",
    "                inconsistent_examples += 1\n",
    "            else:\n",
    "                inconsistent = False\n",
    "        except:\n",
    "            template_error += 1\n",
    "        \n",
    "        for score, _tags, _template in final_topk:\n",
    "            if template_to_tagset[_template] == set(_tags):\n",
    "                pred_tags = _tags\n",
    "                pred_template = _template\n",
    "                break;\n",
    "        \n",
    "        for gold, pred in zip(gold_tags, pred_tags):\n",
    "            total += 1\n",
    "            if gold == pred: \n",
    "                good += 1\n",
    "            else:\n",
    "                perfect = False\n",
    "                \n",
    "        \n",
    "#         for template_id in pred_arg_topk:\n",
    "#             pred_template = vocab_templates.i2w[template_id]\n",
    "#             if template_to_tagset[pred_template] == set(pred_tags):\n",
    "#                 break;\n",
    "    \n",
    "            \n",
    "        if template_to_tagset[pred_template] != set(pred_tags):\n",
    "            tag_set_wrong += 1\n",
    "        \n",
    "        if pred_template == template:\n",
    "            templates_good += 1\n",
    "            if perfect and (not inconsistent):\n",
    "                complete_good += 1\n",
    "        if template in vocab_templates.w2i:\n",
    "            oracle += 1\n",
    "    tok_acc = good / total\n",
    "    \n",
    "    tagset_acc = tag_set_wrong/ len(data)\n",
    "    complete_acc = complete_good / len(data)\n",
    "    template_acc = templates_good / len(data)\n",
    "    oracle_acc = oracle / len(data)\n",
    "    print(inconsistent_examples*1.0/len(data))\n",
    "    print(template_error*1.0/len(data))\n",
    "    print(\"Eval {}-{} Acc: {:>5} Tmpl: {:<5} Tot: {:>5} Orcl: {:>5} Tag: {:>5}\".format(iteration, step, tok_acc, template_acc, complete_acc, oracle_acc, tagset_acc))\n",
    "    return complete_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.0\n",
      "Eval End-test Acc: 0.9962049335863378 Tmpl: 1.0   Tot:   0.5 Orcl:   1.0 Tag:   0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_eval(test[:60], builders, \"End\", \"test\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9627358490566038 Tmpl: 0.48322147651006714 Tot: 0.3668903803131991 Orcl: 0.6935123042505593 Tag: 0.5861297539149888\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9627358490566038 Tmpl: 0.48322147651006714 Tot: 0.3668903803131991 Orcl: 0.6935123042505593 Tag: 0.5861297539149888\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9648584905660378 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5413870246085011\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5324384787472036\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5324384787472036\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5324384787472036\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5324384787472036\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5279642058165548\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5279642058165548\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5279642058165548\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5279642058165548\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9641509433962264 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5279642058165548\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9636792452830188 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5234899328859061\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9627358490566038 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5145413870246085\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9620283018867924 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5078299776286354\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9617924528301887 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5055928411633109\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9617924528301887 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5055928411633109\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9617924528301887 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5055928411633109\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9617924528301887 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5055928411633109\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9617924528301887 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5055928411633109\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9617924528301887 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5055928411633109\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9613207547169811 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5011185682326622\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9613207547169811 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5011185682326622\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9613207547169811 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5011185682326622\n",
      "0.38031319910514544\n",
      "0.0\n",
      "Eval End-test Acc: 0.9613207547169811 Tmpl: 0.48322147651006714 Tot: 0.39373601789709173 Orcl: 0.6935123042505593 Tag: 0.5011185682326622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f3f5b3b19207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"End\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-8d8d5e7c452b>\u001b[0m in \u001b[0;36mrun_eval\u001b[0;34m(data, builders, iteration, step, k)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mword_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtag_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpred_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfinal_topk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_tagging_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mgold_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mperfect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ddeab54d060d>\u001b[0m in \u001b[0;36mbuild_tagging_graph\u001b[0;34m(words, tags, template, builders, train, k)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mseq_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0m_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0marg_topk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mscore_topk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg_topk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \"\"\"\n\u001b[0;32m--> 907\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(50):\n",
    "    run_eval(test, builders, \"End\", \"test\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
